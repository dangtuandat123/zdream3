> ## Documentation Index
> Fetch the complete documentation index at: https://docs.bfl.ml/llms.txt
> Use this file to discover all available pages before exploring further.

# FLUX.2 Image Editing

> Edit images with FLUX.2 using text prompts, multi-reference support, and advanced controls for professional workflows

**Edit images like magic.** Describe what you want changed, and FLUX.2 makes it happen. Combine furniture from multiple photos into one room. Replace people with animals while keeping proportions perfect. Change backgrounds, swap textures, edit text—all while maintaining photorealism that matches professional photography.

Reference multiple images simultaneously - up to 8 via API, up to 10 in the playground. Use **\[max]** for highest precision editing, **\[pro]** for production at scale, **\[flex]** for fine-grained control, or **\[klein]** for cost-efficient high-volume editing.

<Tip>
  **Try it live** - Upload images and describe your edits in our [playground](https://playground.bfl.ai). See the magic happen in seconds.
</Tip>

<Info>
  **Upgrading from FLUX.1?** FLUX.2 adds multi-reference support, improved photorealism, better text editing, and output up to 4MP. [See comparison →](#whats-better-than-flux1)
</Info>

## See It In Action

These aren't demos—they're real edits you can make right now:

<Frame caption="8 images, one prompt: Create a complete fashion editorial with consistent characters across every scene">
  <img src="https://cdn.sanity.io/images/2gpum2i6/production/51696bb4ac2972e1dda5f3e68f748210f392c4f4-4861x1863.jpg" alt="Multi-reference fashion editorial showing consistent characters across 10 scenes" />
</Frame>

**Prompt**: `Create a fashion editorial with consistent characters across multiple scenes`

<Frame caption="Combine furniture from multiple photos into one perfect room, apply textures from other images">
  <img src="https://cdn.sanity.io/images/2gpum2i6/production/8f8f713951ae554d3309c593742b97739c6b0bce-4057x1863.jpg" alt="Interior design combining furniture and textures from multiple reference images" />
</Frame>

**Prompt**: `Use the empty illuminated concrete space from the first image as the room, place all the furniture from the images inside this space, and use the purple knit texture from the uploaded image to create a blanket draped over the red chair.`

<Frame caption="Replace people with animals from 5 different images—proportions and scene composition stay perfect">
  <img src="https://cdn.sanity.io/images/2gpum2i6/production/254b6e382a658da2ad2ed6e27d8cf67f566721aa-4057x1863.jpg" alt="Scene with animals replacing people, maintaining natural proportions" />
</Frame>

**Prompt**: `Replace the people in the image with the animals from images 2, 3, 4, 5, and 6. Adjust them to the space and style so they sit naturally in the scene. Adjust the proportions of the animals to each other and to the space`

<Columns cols={2}>
  <Frame caption="Create scenes using colors from reference images">
    <img src="https://cdn.sanity.io/images/2gpum2i6/production/b756a70b1b5a1686aafe631deb31d88ca7525ddb-1600x1200.png" alt="Color matching from reference" />
  </Frame>

  <Frame caption="Output with matched colors">
    <img src="https://cdn.sanity.io/images/2gpum2i6/production/da31ac8fddaf35a01bce4a5ed22a44c7933d358a-1024x1024.png" alt="Output with color-matched scene" />
  </Frame>
</Columns>

## How It Works

### Multi-Reference Magic

Combine elements from multiple images into one perfect scene. FLUX.2 maintains consistency across characters, products, and styles—even when you're mixing completely different sources. All models support up to 8 reference images via API and up to 10 in the playground.

**Example**: Combine people and animals from separate photos

**Prompt**: `The person from image 1 is petting the cat from image 2, the bird from image 3 is next to them`

<Columns cols={3}>
  <Frame caption="Reference 1: Person">
    <img src="https://cdn.sanity.io/images/2gpum2i6/production/83238423bfee53164679707c8ce6848339f4cf1e-4160x6240.jpg" alt="Person reference" />
  </Frame>

  <Frame caption="Reference 2: Cat">
    <img src="https://cdn.sanity.io/images/2gpum2i6/production/830bfac74da873e1125f41442b4dd1af5a21de7f-3433x5149.jpg" alt="Cat reference" />
  </Frame>

  <Frame caption="Reference 3: Bird">
    <img src="https://cdn.sanity.io/images/2gpum2i6/production/2c2b2e393e1e51e94462e89d5bb879978b66a8a6-3136x3920.jpg" alt="Bird reference" />
  </Frame>
</Columns>

<Frame caption="Result: All elements combined into one natural scene">
  <img src="https://cdn.sanity.io/images/2gpum2i6/production/ec25bcd17f7723c3f5a2ed5d6930d3ccf1d81463-1024x768.jpg" alt="Combined scene with person, cat, and bird" />
</Frame>

### Exact Color Control

FLUX.2 supports precise color matching using hex color codes. Specify exact brand colors without approximation, making it ideal for professional design workflows.

**Color Matching from Reference Images**

Reference a color from another image for precise matching:

**Prompt**: `Change the color of the gloves to the color of image 2`

<Tip>
  For best color matching performance, you can include a color square of the desired color in your reference images and disable Prompt Upsampling. FLUX.2 will match the exact color from the reference.
</Tip>

<Columns cols={2}>
  <Frame caption="Reference image 1">
    <img src="https://cdn.sanity.io/images/2gpum2i6/production/b7b0f5d467e2dc309c7f8e7a1a6fcda92814fc5b-1360x752.jpg" alt="First reference image" />
  </Frame>

  <Frame caption="Color reference">
    <img src="https://cdn.sanity.io/images/2gpum2i6/production/dfebb523d384d4509880ff9eabd33b1db4253919-268x170.png" alt="Second reference image" />
  </Frame>
</Columns>

<Frame caption="Output: The gloves are now the color of the reference image 2">
  <img src="https://cdn.sanity.io/images/2gpum2i6/production/3e8366550cd51f2d1e3dd95ca2a15708a336a702-1360x752.jpg" alt="Output image with gloves changed to the color of reference image 2" />
</Frame>

### Pose Guidance

Control exact positioning and body language. Upload a pose reference image and FLUX.2 matches it precisely—perfect for maintaining consistency across shots or recreating specific poses.

**Example**: Match a pose from a reference image

<Columns cols={3}>
  <Frame caption="Input image">
    <img src="https://cdn.sanity.io/images/2gpum2i6/production/f283eaa49a9c7ec5008fe8785d88b49e75a86a6e-3648x5472.png" alt="Original input image" />
  </Frame>

  <Frame caption="Pose guidance reference">
    <img src="https://cdn.sanity.io/images/2gpum2i6/production/0c7221a85293a97f4981d58bd8fc938dbc8e6840-526x526.png" alt="Pose guidance reference image" />
  </Frame>

  <Frame caption="Result: Exact pose match">
    <img src="https://cdn.sanity.io/images/2gpum2i6/production/b6f1760484612c63e5144f7d0c35f164005f557d-960x1440.png" alt="Output with matched pose" />
  </Frame>
</Columns>

Use pose guidance to:

* Maintain consistent poses across multiple images
* Recreate specific body positions from reference photos
* Control character positioning in scenes
* Match poses from sketches or wireframes

### Extract & Recompose

Isolate products, objects, or elements from images and recompose them into new layouts. Perfect for creating product collages, marketing materials, and Instagram-ready content.

**Example**: Extract products and create an Instagram ad collage

**Prompt**: `Extract the different products from this picture. Clean them up and create a collage from them like it would be for an ad on Instagram`

<Columns cols={2}>
  <Frame caption="Input: Original product image">
    <img src="https://cdn.sanity.io/images/2gpum2i6/production/f3b90881e5969594f38ebe1cb0f73020c13fddee-1053x1520.png" alt="Original product image" />
  </Frame>

  <Frame caption="Output: Clean product collage ready for Instagram">
    <img src="https://cdn.sanity.io/images/2gpum2i6/production/9b9bd8cd77b2a614010f47da1233d22cd6b5f435-992x1440.png" alt="Product collage extracted and recomposed" />
  </Frame>
</Columns>

Use extraction to:

* Create product showcases from lifestyle photos
* Build marketing collages from product shots
* Isolate elements for social media content
* Clean up and recompose product catalogs

### Advanced Multi-Reference Techniques

**Collage Method**

<Info>
  Quality may be slightly lower with the collage method compared to using multiple separate input images. For best results, use individual reference images when possible.
</Info>

You can also use a single input image containing a collage layout to guide composition. This method is useful for quick layout experiments.

**Prompt**: `Create a cinematic street scene in front of the pastel-colored corner building. The man in the dark suit is leaning against the wall near the café entrance. The woman is walking past him, carrying one of the Azzedine Alaïa tote bags. The focus is on their contrasting styles — her relaxed, creative vibe versus his confident, formal look. The black boots are part of her outfit`

<Columns cols={2}>
  <Frame caption="Input: Collage with reference elements">
    <img src="https://cdn.sanity.io/images/2gpum2i6/production/8f171eb875ef7d921453a2b51481e918c9fe79a5-1707x1533.jpg" alt="Collage input with building, people, and accessories" />
  </Frame>

  <Frame caption="Output: Composed scene from collage elements">
    <img src="https://cdn.sanity.io/images/2gpum2i6/production/fc1a2d78c8e6066a32e7e379557b98b1920812f3-1440x1280.jpg" alt="Cinematic street scene composed from collage elements" />
  </Frame>
</Columns>

## Using FLUX.2 API for Image Editing

FLUX.2 image editing **requires both** a **text prompt** and **an input image** to work. The input image serves as the base that will be edited according to your prompt. You can optionally include additional reference images for multi-reference editing:

* **\[max]**: Up to **8 reference images** via API, up to **10** in playground
* **\[pro]**: Up to **8 reference images** via API, up to **10** in playground
* **\[flex]**: Up to **8 reference images** via API, up to **10** in playground
* **\[klein]**: Up to **4 reference images** via API
* **\[dev]**: Recommended max **6 reference images** (open model, limited by memory)

To use FLUX.2 for image editing, you'll make a request to `/v1/flux-2-max`, `/v1/flux-2-pro`, `/v1/flux-2-flex`, `/v1/flux-2-klein-4b`, or `/v1/flux-2-klein-9b`:

### Create Request

<CodeGroup>
  ```bash create_request.sh theme={null}
  # Using image URLs (simplest method)
  request=$(curl -X POST \
    'https://api.bfl.ai/v1/flux-2-pro' \
    -H 'accept: application/json' \
    -H "x-key: ${BFL_API_KEY}" \
    -H 'Content-Type: application/json' \
    -d '{
      "prompt": "<What you want to edit on the image>",
      "input_image": "https://example.com/your-image.jpg",
      "input_image_2": "https://example.com/reference-2.jpg"
    }')
  echo $request
  request_id=$(echo $request | jq -r .id)
  polling_url=$(echo $request | jq -r .polling_url)
  ```

  ```python create_request.py theme={null}
  import os
  import requests

  # Option 1: Use image URLs directly (simplest)
  response = requests.post(
      'https://api.bfl.ai/v1/flux-2-pro',
      headers={
          'accept': 'application/json',
          'x-key': os.environ.get("BFL_API_KEY"),
          'Content-Type': 'application/json',
      },
      json={
          'prompt': '<What you want to edit on the image>',
          'input_image': 'https://example.com/your-image.jpg',
          # 'input_image_2': 'https://example.com/reference-2.jpg',  # Optional
      },
  ).json()

  request_id = response["id"]
  polling_url = response["polling_url"]
  cost = response.get("cost")  # Cost in credits

  # Option 2: Use base64 encoded images (for local files)
  # import base64
  # from PIL import Image
  # from io import BytesIO
  #
  # image = Image.open("your_image.jpg")
  # buffered = BytesIO()
  # image.save(buffered, format="JPEG")
  # img_str = base64.b64encode(buffered.getvalue()).decode()
  # # Then use img_str as the input_image value
  ```

  ```python create_request_klein_4b.py theme={null}
  import os
  import requests

  # FLUX.2 [klein] 4B - Cost-efficient image editing
  response = requests.post(
      'https://api.bfl.ai/v1/flux-2-klein-4b',
      headers={
          'accept': 'application/json',
          'x-key': os.environ.get("BFL_API_KEY"),
          'Content-Type': 'application/json',
      },
      json={
          'prompt': '<What you want to edit on the image>',
          'input_image': 'https://example.com/your-image.jpg',
          # 'input_image_2': 'https://example.com/reference-2.jpg',  # Up to 4 total
      },
  ).json()

  request_id = response["id"]
  polling_url = response["polling_url"]
  ```

  ```python create_request_klein_9b.py theme={null}
  import os
  import requests

  # FLUX.2 [klein] 9B - Balanced quality/speed
  response = requests.post(
      'https://api.bfl.ai/v1/flux-2-klein-9b',
      headers={
          'accept': 'application/json',
          'x-key': os.environ.get("BFL_API_KEY"),
          'Content-Type': 'application/json',
      },
      json={
          'prompt': '<What you want to edit on the image>',
          'input_image': 'https://example.com/your-image.jpg',
          # 'input_image_2': 'https://example.com/reference-2.jpg',  # Up to 4 total
      },
  ).json()

  request_id = response["id"]
  polling_url = response["polling_url"]
  ```
</CodeGroup>

A successful response will be a JSON object containing the request's `id`, `polling_url`, and pricing information:

```json Response Example theme={null}
{
  "id": "task-id-here",
  "polling_url": "https://api.bfl.ai/v1/get_result?id=task-id-here",
  "cost": 4.5,           // Credits charged for this request
  "input_mp": 2.07,      // Input megapixels
  "output_mp": 2.07      // Output megapixels
}
```

The `cost` field shows the credits charged for the request. Use this to track pricing for your image editing operations.

### Poll for Result

After submitting a request, you need to poll using the returned `polling_url` to retrieve the output when ready.

<CodeGroup>
  ```bash poll_result.sh theme={null}
  while true; do
    sleep 0.5
    result=$(curl -s -X 'GET' \
      "${polling_url}" \
      -H 'accept: application/json' \
      -H "x-key: ${BFL_API_KEY}")
    
    status=$(echo $result | jq -r .status)
    echo "Status: $status"
    
    if [ "$status" == "Ready" ]; then
      echo "Result: $(echo $result | jq -r .result.sample)"
      break
    elif [ "$status" == "Error" ] || [ "$status" == "Failed" ]; then
      echo "Generation failed: $result"
      break
    fi
  done
  ```

  ```python poll_result.py theme={null}
  # This assumes that the `polling_url` variable is set.

  import time
  import os
  import requests

  while True:
    time.sleep(0.5)
    result = requests.get(
        polling_url,
        headers={
            'accept': 'application/json',
            'x-key': os.environ.get("BFL_API_KEY"),
        },
        params={'id': request_id}
    ).json()
    
    if result['status'] == 'Ready':
        print(f"Image ready: {result['result']['sample']}")
        break
    elif result['status'] in ['Error', 'Failed']:
        print(f"Generation failed: {result}")
        break
  ```
</CodeGroup>

A successful response will be a JSON object containing the result, and `result['sample']` is a signed URL for retrieval.

<Warning>
  Our signed URLs are only valid for 10 minutes. Please retrieve your result within this timeframe.
</Warning>

### FLUX.2 Image Editing Parameters

<Tip>
  For image editing, FLUX.2 matches input image dimensions by default (rounded to multiples of 16). Use `width` and `height` to override.

  **Resolution:**

  * **Minimum**: 64x64
  * **Maximum**: 4MP (e.g., 2048x2048)
  * **Recommended**: Up to 2MP
  * **Output**: Always multiples of 16
</Tip>

<Warning>
  **Input image preprocessing:** FLUX.2 automatically preprocesses input images to meet resolution requirements:

  * **Images over 4MP** are resized to 4MP while preserving the aspect ratio (dimensions rounded to multiples of 16 pixels)
  * **Non-aligned dimensions** are cropped to the next smaller multiple of 16 pixels on each edge

  This means your input image may be slightly modified before processing. If pixel-perfect alignment matters for your use case, ensure your input images are already at 4MP or below with dimensions that are multiples of 16.
</Warning>

List of FLUX.2 parameters for image editing via the `/v1/flux-2-pro` and `/v1/flux-2-flex` endpoints:

| Parameter                               | Type           | Default  | Description                                                                                                                                                                                                                         | Required |
| --------------------------------------- | -------------- | -------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------- |
| `prompt`                                | string         |          | Text description of the edit to be applied. Supports up to **32K tokens** for long-form prompts.                                                                                                                                    | **Yes**  |
| `input_image`                           | string         |          | Base64 encoded image or URL of image to use as reference. Supports up to 20MB or 20 megapixels. Input resolution: minimum **64x64**, recommended up to 2MP, maximum 4MP (e.g., 2048x2048). Dimensions must be multiples of 16.      | **Yes**  |
| `input_image_2` through `input_image_8` | string         | `null`   | Additional reference images for multi-reference editing. Each parameter accepts base64 encoded image or URL. Up to 7 additional images (8 total) via API for all models. **\[dev]**: Recommended max 5 additional images (6 total). | No       |
| `width`                                 | integer / null | `null`   | Output width in pixels. Must be a multiple of 16. If omitted, matches input image width.                                                                                                                                            | No       |
| `height`                                | integer / null | `null`   | Output height in pixels. Must be a multiple of 16. If omitted, matches input image height.                                                                                                                                          | No       |
| `seed`                                  | integer / null | `null`   | Seed for reproducibility. If `null` or omitted, a random seed is used. Accepts any integer.                                                                                                                                         | No       |
| `safety_tolerance`                      | integer        | `2`      | Moderation level for inputs and outputs. Value ranges from 0 (most strict) to 5 (more permissive).                                                                                                                                  | No       |
| `output_format`                         | string         | `"jpeg"` | Desired format of the output image. Can be "jpeg" or "png".                                                                                                                                                                         | No       |
| `guidance`                              | number / null  | `4.5`    | **\[flex only]** Guidance scale for generation. Controls how closely the output follows the prompt. Minimum: 1.5, maximum: 10, default: 4.5.                                                                                        | No       |
| `steps`                                 | integer / null | `50`     | **\[flex only]** Number of inference steps. Maximum: 50, default: 50.                                                                                                                                                               | No       |
| `webhook_url`                           | string / null  | `null`   | URL for asynchronous completion notification. Must be a valid HTTP/HTTPS URL.                                                                                                                                                       | No       |
| `webhook_secret`                        | string / null  | `null`   | Secret for webhook signature verification, sent in the `X-Webhook-Secret` header.                                                                                                                                                   | No       |

### Multi-Reference Editing

When using multiple `input_image` parameters (`input_image`, `input_image_2`, `input_image_3`, etc.), FLUX.2 combines elements from multiple source images while maintaining consistency. This is particularly useful for:

* **Character consistency**: Maintain the same character across different scenes
* **Product mockups**: Use product reference images in various contexts
* **Style transfer**: Combine style references with content images
* **Fashion editorials**: Keep models and clothing consistent across variations

FLUX.2 understands your input images, making it possible to describe what you want to change using natural language. You can reference specific images by index number or describe elements from your input images.

**Example 1: Natural Language Descriptions**

Describe elements from your input images naturally, and FLUX.2 understands them:

**Prompt**: `The man is leaning against the wall reading a newspaper with the title "FLUX.2". The woman is walking past him, carrying one of the tote bags and wearing the black boots. The focus is on their contrasting styles — her relaxed, creative vibe versus his formal look.`

<Note>
  FLUX.2 intelligently identifies elements across multiple input images based on your descriptions, even when you don't specify exact image indices.
</Note>

**Example 2: Explicit Image Indexing**

Reference specific images by number for precise control:

**Prompt**: `Replace the top of the person from image 1 with the one from image 2`

This approach gives you explicit control over which elements come from which reference image.

**Example 3: Combining Multiple People**

Combine people from different images into a single scene:

**Prompt**: `This exact image but the couple next to the fire replaced by the people in image 2 and 3`

**API Example**: Multi-reference editing with multiple input images

```python Multi-Reference Editing Example theme={null}
import requests
import os

api_key = os.environ.get("BFL_API_KEY")

response = requests.post(
    'https://api.bfl.ai/v1/flux-2-pro',
    headers={"x-key": api_key},
    json={
        "prompt": "The person from image 1 is petting the cat from image 2, the bird from image 3 is next to them",
        "input_image": "https://example.com/person.jpg",      # URL or base64
        "input_image_2": "https://example.com/cat.jpg",       # URL or base64
        "input_image_3": "https://example.com/bird.jpg",      # URL or base64
        "seed": 42,
        "output_format": "jpeg"
    }
)

request_id = response.json()["id"]
```

<Note>
  Use `input_image` for the main image, and `input_image_2` through `input_image_8` for additional reference images (up to 8 total via API). All models support up to 10 reference images in the playground. **\[dev]** recommended max 6 total.
</Note>

### Choosing the Right Model

|                      | **\[klein]**                                       | **\[max]**                        | **\[pro]**                     | **\[flex]**                    |
| -------------------- | -------------------------------------------------- | --------------------------------- | ------------------------------ | ------------------------------ |
| **Best for**         | Real-time editing, high volume                     | Highest quality, final production | Production workflows at scale  | Quality with control           |
| **Speed**            | Sub-second                                         | \< 15 seconds                     | \< 10 seconds                  | Higher latency                 |
| **Reference images** | Up to 4 (API)                                      | Up to 8 (API), 10 (playground)    | Up to 8 (API), 10 (playground) | Up to 8 (API), 10 (playground) |
| **Controls**         | Standard                                           | Standard                          | Standard                       | Adjustable steps & guidance    |
| **Grounding search** | No                                                 | Yes                               | No                             | No                             |
| **Pricing**          | 4B: $0.014 + $0.001/MP<br />9B: $0.015 + $0.002/MP | from \$0.07/MP                    | from \$0.03/MP                 | \$0.06/MP                      |

<CardGroup cols={2}>
  <Card title="FLUX.2 [klein]" icon="rocket" href="/flux_2/flux2_overview#flux2-klein-models">
    **Sub-Second Editing**

    Real-time image editing from \$0.014/image. Open weights available—runs locally on consumer GPUs (\~13GB VRAM).
  </Card>

  <Card title="FLUX.2 [max]" icon="crown">
    **Top-Tier Quality**

    Highest precision editing with state-of-the-art character consistency. Best for professional content needing the final touch.
  </Card>

  <Card title="FLUX.2 [pro]" icon="bolt">
    **Fast & Efficient**

    Best balance of speed and quality. Ideal for high-volume editing workflows.
  </Card>

  <Card title="FLUX.2 [flex]" icon="sliders">
    **Quality with Control**

    Adjustable steps and guidance. Best when you need fine-grained control over generation.
  </Card>
</CardGroup>

## What's Better Than FLUX.1

| Capability             | FLUX.1                        | FLUX.2                                                                                                   |
| ---------------------- | ----------------------------- | -------------------------------------------------------------------------------------------------------- |
| Multi-reference images | 1 image                       | **\[pro]**: Up to 8 (API), 10 (playground)<br />**\[flex]**: Up to 10<br />**\[dev]**: Recommended max 6 |
| Output resolution      | Up to 1.6MP (except \[ultra]) | Up to 4MP                                                                                                |
| Text editing           | Basic                         | Improved accuracy                                                                                        |
| Photorealism           | Good                          | Higher fidelity on skin, hair, fabric, hands                                                             |
| Prompt following       | Standard                      | Enhanced complex instruction handling                                                                    |
| World knowledge        | Limited                       | More grounded in lighting and spatial logic                                                              |
